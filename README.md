# RecLM: Recommendation Instruction Tuning

<img src="./figures/RecLM_fig.png" style="zoom:100%;" />

This is the codes and dataset for **RecLM** proposed in the paper **RecLM: Recommendation Instruction Tuning**.

### Introduction

In this work, the authors introduce a model-agnostic instruction tuning framework RecLM. It can be seamlessly integrated into existing recommendation systems as a plug-and-play component, significantly enhancing their generalization capacity in scenarios with limited data. The authors integrate large language models with collaborative filtering to enhance user profiling, particularly in cold-start scenarios, where current methods often struggle. Additionally, this approach employs reinforcement learning to refine profile quality, effectively addressing challenges associated with data noise and over-smoothing. In order to conduct comprehensive evaluation, the authors integrate RecLM with a range of state-of-the-art recommenders to assess the effectiveness of the proposed approach across various settings.

<img src="./figures/model.png" style="zoom:100%;" />

## ğŸ“ Environment

For running base recommendation models:

- python==3.9.13

- numpy==1.23.1

- torch==1.11.0

- scipy==1.9.1

For tuning LLMs:

- wandb==0.16.2 

- transformers== 4.36.2

- trl==0.7.9

- peft==0.7.2

## ğŸš€ How to run the codes

**1. Tuning Llama 2 via Lora.**

```
cd ./llm/lora/
```

For conducting LLM fine-tuning through knowledge distillation (user side):

```
python sft_base.py
```

For conducting collaborative instruction tuning (user side):

```
python sft_base_mask.py
```

For conducting reinforcement learning-based personalized feature enhancement (user side).

```
cd ./rlhf/
```

- Training the reward model:

```
python reward_modeling.py
```

- Proximal policy optimization:

```
python rl_training.py
```

For conducting collaborative instruction tuning (item side):

```
python sft_base_item.py
```

**2. User/Item profile generation.**

- User profile generation (only knowledge distillation)

```
python inference_base.py
```

- User profile generation (with collaborative instrucntion tuning and reinforcement learning enhancement)

```
python inference_base_mask.py
```

- Item profile generation

```
python inference_base_item.py
```

**Note**: We provide the llama weights that have undergone collaborative instruction tuning and reinforcement learning enhancement on the MIND and Netflix datasets in the Hugging Face repository (https://huggingface.co/hkuds/RecLM_model). Please download the corresponding model weight files before performing profile inference.

**3. Running base recommendation models integrated with generated user/item profiles.**

For running base recommendation models (e.g., BiasMF):

```python
cd ./base_models/BiasMF/
python Main.py --data {dataset}
```

## ğŸ¯ Experimental Results

**Performance comparison on MIND, Netflix and Industrial data in terms of *Recall* and *NDCG*:**

<img src="./figures/exp.png" style="zoom:100%;" />

## ğŸ“š Datasets

**Statistics of the experimental datasets:**

| Statistics       | MIND    | Netflix | Industrial |
| ---------------- | ------- | ------- | ---------- |
| # User           | 57128   | 16835   | 117433     |
| # Overlap. Item  | 1020    | 6232    | 72417      |
| # Snapshot       | daily   | yearly  | daily      |
| **Training Set** |         |         |            |
| # Item           | 2386    | 6532    | 152069     |
| # Interactions   | 89734   | 1655395 | 858087     |
| # Sparsity       | 99.934% | 98.495% | 99.995%    |
| **Test Set**     |         |         |            |
| # Item           | 2461    | 8413    | 158155     |
| # Interactions   | 87974   | 1307051 | 876415     |
| # Sparsity       | 99.937% | 99.077% | 99.995%    |

## ğŸ‘‰ Code Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ TextEncoder.py
â”œâ”€â”€ base_models
â”‚Â Â  â”œâ”€â”€ BiasMF
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ DataHandler.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Main.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Model.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Params.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ Utils
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ TimeLogger.py
â”‚Â Â  â”‚Â Â      â””â”€â”€ Utils.py
â”‚Â Â  â”œâ”€â”€ LightGCN
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ DataHandler.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Main.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Model.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Params.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ Utils
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ TimeLogger.py
â”‚Â Â  â”‚Â Â      â””â”€â”€ Utils.py
â”‚Â Â  â”œâ”€â”€ NCF
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ DataHandler.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Main.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Model.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Params.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ Utils
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ TimeLogger.py
â”‚Â Â  â”‚Â Â      â””â”€â”€ Utils.py
â”‚Â Â  â”œâ”€â”€ SGL
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ DataHandler.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Main.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Model.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Params.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ Utils
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ TimeLogger.py
â”‚Â Â  â”‚Â Â      â””â”€â”€ Utils.py
â”‚Â Â  â””â”€â”€ SimGCL
â”‚Â Â      â”œâ”€â”€ DataHandler.py
â”‚Â Â      â”œâ”€â”€ Main.py
â”‚Â Â      â”œâ”€â”€ Model.py
â”‚Â Â      â”œâ”€â”€ Params.py
â”‚Â Â      â””â”€â”€ Utils
â”‚Â Â          â”œâ”€â”€ TimeLogger.py
â”‚Â Â          â””â”€â”€ Utils.py
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ README.md
â”‚Â Â  â”œâ”€â”€ mind
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ gpt_output_dict_item_side_filter.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ item_id_map_test.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ item_id_map_train.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ item_id_map_zero.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ item_info_dict.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ item_original_features.npy
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ item_profile
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ item_profile_embeddings.npy
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ maskMat_zero.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ self_instruction_dict.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ self_instruction_dict_item.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ trnMat_zero.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tstMat_zero_.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tstMat_zero_shot.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ user_item_dict_test.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ user_item_dict_train.pkl
â”‚Â Â  â”‚Â Â  â””â”€â”€ user_profile
â”‚Â Â  â””â”€â”€ netflix
â”‚Â Â      â”œâ”€â”€ gpt_output_dict_item_side_filter.pkl
â”‚Â Â      â”œâ”€â”€ item_id_map_test.pkl
â”‚Â Â      â”œâ”€â”€ item_id_map_train.pkl
â”‚Â Â      â”œâ”€â”€ item_id_map_zero.pkl
â”‚Â Â      â”œâ”€â”€ item_info_dict.pkl
â”‚Â Â      â”œâ”€â”€ item_original_features.npy
â”‚Â Â      â”œâ”€â”€ item_profile
â”‚Â Â      â”‚Â Â  â””â”€â”€ item_profile_embeddings.npy
â”‚Â Â      â”œâ”€â”€ maskMat_zero.pkl
â”‚Â Â      â”œâ”€â”€ self_instruction_dict.pkl
â”‚Â Â      â”œâ”€â”€ self_instruction_dict_item.pkl
â”‚Â Â      â”œâ”€â”€ self_instruction_dict_item_full.pkl
â”‚Â Â      â”œâ”€â”€ trnMat_zero.pkl
â”‚Â Â      â”œâ”€â”€ tstMat_zero_.pkl
â”‚Â Â      â”œâ”€â”€ tstMat_zero_shot.pkl
â”‚Â Â      â”œâ”€â”€ user_item_dict_test.pkl
â”‚Â Â      â”œâ”€â”€ user_item_dict_train.pkl
â”‚Â Â      â””â”€â”€ user_profile
â”‚Â Â          â””â”€â”€ user_profile_embeddings.npy.zip
â”œâ”€â”€ figures
â”‚Â Â  â”œâ”€â”€ RecLM_fig.png
â”‚Â Â  â”œâ”€â”€ exp.png
â”‚Â Â  â””â”€â”€ model.png
â”œâ”€â”€ llm
â”‚Â Â  â”œâ”€â”€ ft_models
â”‚Â Â  â”‚Â Â  â””â”€â”€ README.md
â”‚Â Â  â””â”€â”€ lora
â”‚Â Â      â”œâ”€â”€ convert_llama_weights_to_hf.py
â”‚Â Â      â”œâ”€â”€ inference_base.py
â”‚Â Â      â”œâ”€â”€ inference_base_item.py
â”‚Â Â      â”œâ”€â”€ inference_base_mask.py
â”‚Â Â      â”œâ”€â”€ make_dataset.py
â”‚Â Â      â”œâ”€â”€ merge_model.py
â”‚Â Â      â”œâ”€â”€ rlhf
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ accuracy.py
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ reward_modeling.py
â”‚Â Â      â”‚Â Â  â””â”€â”€ rl_training.py
â”‚Â Â      â”œâ”€â”€ sft_base.py
â”‚Â Â      â”œâ”€â”€ sft_base_item.py
â”‚Â Â      â”œâ”€â”€ sft_base_mask.py
â”‚Â Â      â””â”€â”€ sft_base_naive.py
â””â”€â”€ sft_data
    â”œâ”€â”€ mind
    â”‚Â Â  â”œâ”€â”€ cf_instruction_data.csv
    â”‚Â Â  â”œâ”€â”€ cf_instruction_hf
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ data-00000-of-00001.arrow
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dataset_info.json
    â”‚Â Â  â”‚Â Â  â””â”€â”€ state.json
    â”‚Â Â  â”œâ”€â”€ item_side_instruction_data.csv
    â”‚Â Â  â”œâ”€â”€ item_side_instruction_hf
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ data-00000-of-00001.arrow
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dataset_info.json
    â”‚Â Â  â”‚Â Â  â””â”€â”€ state.json
    â”‚Â Â  â”œâ”€â”€ mind_fine_tune.csv
    â”‚Â Â  â”œâ”€â”€ mind_hf
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ data-00000-of-00001.arrow
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dataset_info.json
    â”‚Â Â  â”‚Â Â  â””â”€â”€ state.json
    â”‚Â Â  â””â”€â”€ rlhf
    â”‚Â Â      â”œâ”€â”€ eval.csv
    â”‚Â Â      â”œâ”€â”€ rl.csv
    â”‚Â Â      â””â”€â”€ train.csv
    â””â”€â”€ netflix
        â”œâ”€â”€ cf_instruction_data.csv
        â”œâ”€â”€ cf_instruction_hf
        â”‚Â Â  â”œâ”€â”€ data-00000-of-00001.arrow
        â”‚Â Â  â”œâ”€â”€ dataset_info.json
        â”‚Â Â  â””â”€â”€ state.json
        â”œâ”€â”€ item_side_instruction_data.csv
        â”œâ”€â”€ item_side_instruction_hf
        â”‚Â Â  â”œâ”€â”€ data-00000-of-00001.arrow
        â”‚Â Â  â”œâ”€â”€ dataset_info.json
        â”‚Â Â  â””â”€â”€ state.json
        â”œâ”€â”€ netflix_fine_tune.csv
        â”œâ”€â”€ netflix_hf
        â”‚Â Â  â”œâ”€â”€ data-00000-of-00001.arrow
        â”‚Â Â  â”œâ”€â”€ dataset_info.json
        â”‚Â Â  â””â”€â”€ state.json
        â””â”€â”€ rlhf
            â”œâ”€â”€ eval.csv
            â”œâ”€â”€ rl.csv
            â””â”€â”€ train.csv
```

## ğŸŒŸ Citation

If you find this work helpful to your research, please kindly consider citing our paper.
